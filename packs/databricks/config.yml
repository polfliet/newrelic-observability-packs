id: 924fd4b3-a6d1-4a6e-9e2c-b598f197f713

# Name of the pack (required)
name: databricks
title: Databricks Integration
description: >-
  Databricks is an orchestration platform for Apache Spark. Instantly monitor Databricks Spark applications with our New Relic Spark integration quickstart.
  Our integration provides a script run in a notebook to generate an installation script, which you can attach to a cluster and populate Spark metrics to New relic Insights events. Easily track the health of your Databricks clusters, fine-tune your Spark jobs for peak performance, and troubleshoot problems with this quickstart.

  Databricks clusterâ€™s driver node runs each job in scheduled stages. Individual stages are broken down into tasks and distributed across executor nodes. Our New Relic Spark integration collects detailed job and stage metrics so you can get granular insight into job performance at a glance. For example , break down the Job metric by status (successful, pending, or failed) to see in real-time if a high number of jobs are failing, which could indicate a code error or memory issue at the executor level. Metrics on the number of jobs in realtime can also help you make decisions for provisioning clusters in the future.


summary: >-
  Monitor Databricks Spark applications with New Relic Spark integration using notebook script

icon: icon.png
logo: logo.png
# Support level: New Relic | Verified | Community (required)
level: Community

website: https://databricks.com/

keywords:
  - nrlabs
  - nrlabs-data
  - apache spark
  - spark
  - databricks

# Authors of the pack (required)
authors:
  - New Relic Labs

documentation:
  - name: Databricks init script creator notebook
    description: >-
      Databricks notebook to create init script to be used during initialization of Databricks cluster
    url: https://github.com/newrelic-experimental/nri-spark#databricks-init-script-creator-notebook

installPlans:
  - third-party-databricks
